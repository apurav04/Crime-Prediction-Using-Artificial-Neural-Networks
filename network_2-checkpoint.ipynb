{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199cfb5-c108-4278-813f-01f34c2f340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File loaded from Github Repo\n",
    "file_path = 'final_crime.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Removing invalid points\n",
    "df = df[pd.isnull(df['NEIGHBOURHOOD']) != pd.isnull(pd.NaT)]\n",
    "\n",
    "\n",
    "df = df[['YEAR','MONTH','DAY', 'HOUR', 'Neighbourhood', 'Latitude', 'Longitude']] \n",
    "print(\"Shape of Dataset imported for use: \" + str(df.shape) + \"\\n\")\n",
    "\n",
    "print(\"Sample row\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608223b-2fb6-44e6-9806-a4daa5258650",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"------ Adding date-time object as key ------\\n\")\n",
    "date_time_col = pd.to_datetime(df[['YEAR', 'MONTH', 'DAY', 'HOUR']])\n",
    "\n",
    "# Make the added Date the index of the dataset\n",
    "df['DateTimeMix'] = date_time_col\n",
    "df.set_index('DateTimeMix', inplace=True)\n",
    "\n",
    "print(\"Sample row\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcabe6-f6a2-4bc6-9fb9-3af54969d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Crime'] = 1\n",
    "print(\"Sample row\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f188f-6c1d-47b8-9747-4255b11601e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_file_path = 'https://raw.githubusercontent.com/NasirKhalid24/ELE494-Project/master/Datasets/cov_localareas.csv'\n",
    "\n",
    "neighbourhoods = pd.read_csv(nb_file_path)\n",
    "print(\"List of Neighbourhoods : \")\n",
    "neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1e4da-71ed-415b-b463-e880dea92c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in neighbourhoods['NAME']:\n",
    "    subset = df[df['Neighbourhood'] == i]\n",
    "    crime_extra = subset.groupby(level=0).count().resample('1H').asfreq()\n",
    "    crime_extra = crime_extra[pd.isna((crime_extra['Crime']))]\n",
    "  \n",
    "    if(crime_extra.shape[0] != 0 ):\n",
    "        crime_extra['Crime'] = 0\n",
    "        crime_extra['YEAR'] = crime_extra.index.year\n",
    "        crime_extra['MONTH'] = crime_extra.index.month\n",
    "        crime_extra['DAY'] = crime_extra.index.day\n",
    "        crime_extra['HOUR'] = crime_extra.index.hour\n",
    "\n",
    "        crime_extra['Neighbourhood'] = i\n",
    "\n",
    "\n",
    "        df = df.append(crime_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278dc96c-2eac-4567-8111-7bb9267b199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Crime'].values\n",
    "# X = df[['YEAR','MONTH','DAY', 'HOUR', 'Latitude', 'Longitude', 'Graffiti', 'Drinking_Fountain']].values\n",
    "\n",
    "neigh = df['Neighbourhood']\n",
    "onehot_neigh = pd.get_dummies(neigh)\n",
    "X = np.concatenate((df[['YEAR','MONTH','DAY', 'HOUR']].values, onehot_neigh.values), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0bfd29-25cd-49fd-8d00-2b94d6ab9cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2bb788-9249-4c05-b802-ab6e7172319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c25108-b9f9-45b7-aac5-5ac4759702a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b894b6b8-239a-46c6-8507-97c7c5a2ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=101)\n",
    "\n",
    "print(\"Training Data Size: \" + str(X_train.shape))\n",
    "print(\"Testing Data Size:\" + str(X_test.shape))\n",
    "print(\"Training Label Size: \" + str(Y_train.shape))\n",
    "print(\"Testing Label Size: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079d24c-96e8-4a65-a3b5-e23588196ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to plot loss and accuracy vs epochs\n",
    "def loss_curve(history):\n",
    "  train_loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "  x_axis     = range(1, len(history.history['loss'])+1)\n",
    "  \n",
    "  plt.figure()\n",
    "  plt.plot(x_axis, train_loss, label=\"Training Loss\")\n",
    "  plt.plot(x_axis, val_loss, label=\"Validation Loss\")\n",
    "  plt.ylabel('Loss Value')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.title('Epochs vs Loss')\n",
    "  plt.legend()\n",
    "  \n",
    "def accuracy(history):\n",
    "  acc  = history.history['acc']\n",
    "  val_acc = history.history['val_acc']\n",
    "  x_axis     = range(1, len(history.history['acc'])+1)\n",
    "  \n",
    "  plt.figure()\n",
    "  plt.plot(x_axis, np.dot(acc,100), label=\"Accuracy\")\n",
    "  plt.plot(x_axis, np.dot(val_acc, 100), label=\"Validation Accuracy\")\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.title('Epochs vs Accuracy')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043e216-81ae-4b65-ae59-554bc5ce4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1], ) ) )\n",
    "model.add(Dense(128, activation='relu') )\n",
    "model.add(Dense(512, activation='relu') )\n",
    "model.add(Dense(128, activation='relu') )\n",
    "model.add(Dense(64, activation='relu') )\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid') )\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa276b7-4786-44dc-8427-2699425ebf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "          epochs = 15,\n",
    "          batch_size=512,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082762d-934f-4d3d-881f-f2fce324443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curve(history)\n",
    "accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7352e-bc6f-4524-b164-fd06b2765886",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(onehot_neigh.columns.values)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Test Loss: \" + str(test_loss))\n",
    "print(\"Test Accuracy: \" + str(test_acc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0002b32-f7cd-4b44-a9bb-1a435dfe89bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[2019, 2, 11, 3,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])\n",
    "\n",
    "test = scaler.transform(test)\n",
    "ans = model.predict(test)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3fc3c9-8de3-4dbb-9aaf-4239525ddb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[2019, 2, 11, 12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0]])\n",
    "test = scaler.transform(test)\n",
    "ans = model.predict(test)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff7ccd-5c81-427b-b509-f72d01aa2c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 24):\n",
    "#   test = np.array([[2012, 1, 1, i, 49.284645, -123.136306, DistanceToGraffiti(49.284645, -123.136306), DistanceToFountain(49.284645, -123.136306)]])\n",
    "  test = np.array([[2005, 12,31, i,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])\n",
    "\n",
    "  test = scaler.transform(test)\n",
    "  ans = model.predict(test)\n",
    "  print(\"Likelihood of crime at \" + str(i) + \" hour: \" + str(ans[0][0]*100) + \" %\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb3322-119f-4ef9-9c8e-825d6dd6296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b57469-a589-487c-b2b5-e2105adf394d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
